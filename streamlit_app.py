import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="CRISP-DM ç·šæ€§è¿´æ­¸ç¯„ä¾‹", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ¨™é¡Œ
st.title("ğŸ”¬ CRISP-DM ç·šæ€§è¿´æ­¸äº’å‹•ç¯„ä¾‹")
st.markdown("---")

# å´é‚Šæ¬„ - åƒæ•¸è¨­å®š
st.sidebar.header("ğŸ“Š è³‡æ–™åƒæ•¸è¨­å®š")

# 1. è³‡æ–™ç”Ÿæˆåƒæ•¸
n_points = st.sidebar.slider(
    "è³‡æ–™é»æ•¸é‡ (n)", 
    min_value=100, 
    max_value=1000, 
    value=500, 
    step=50,
    help="ç”Ÿæˆå¤šå°‘å€‹è³‡æ–™é»"
)

coefficient_a = st.sidebar.slider(
    "ç·šæ€§ä¿‚æ•¸ (a)", 
    min_value=-10.0, 
    max_value=10.0, 
    value=2.0, 
    step=0.1,
    help="y = ax + b + noise ä¸­çš„ä¿‚æ•¸ a"
)

intercept_b = st.sidebar.slider(
    "æˆªè· (b)", 
    min_value=-20.0, 
    max_value=20.0, 
    value=5.0, 
    step=0.5,
    help="y = ax + b + noise ä¸­çš„æˆªè· b"
)

noise_variance = st.sidebar.slider(
    "é›œè¨Šè®Šç•°æ•¸ (var)", 
    min_value=0, 
    max_value=1000, 
    value=100, 
    step=10,
    help="é›œè¨Šçš„è®Šç•°æ•¸ï¼Œå½±éŸ¿è³‡æ–™çš„åˆ†æ•£ç¨‹åº¦"
)

# è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾
random_seed = st.sidebar.number_input(
    "éš¨æ©Ÿç¨®å­", 
    min_value=0, 
    max_value=9999, 
    value=42,
    help="è¨­å®šéš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾"
)

# CRISP-DM éšæ®µæ¨™ç¤º
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ”„ CRISP-DM éšæ®µ")
st.sidebar.markdown("âœ… 1. å•†æ¥­ç†è§£")
st.sidebar.markdown("âœ… 2. è³‡æ–™ç†è§£") 
st.sidebar.markdown("âœ… 3. è³‡æ–™æº–å‚™")
st.sidebar.markdown("âœ… 4. å»ºæ¨¡")
st.sidebar.markdown("âœ… 5. è©•ä¼°")
st.sidebar.markdown("âœ… 6. éƒ¨ç½²")

# ä¸»è¦å…§å®¹å€åŸŸ
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ“ˆ ç·šæ€§è¿´æ­¸è¦–è¦ºåŒ–")
    
    # ç”Ÿæˆè³‡æ–™ (CRISP-DM 3.0 è³‡æ–™æº–å‚™)
    np.random.seed(random_seed)
    x = np.random.rand(n_points) * 20 - 10  # xç¯„åœï¼š-10åˆ°10
    y_true = coefficient_a * x + intercept_b
    noise = np.random.normal(0, np.sqrt(noise_variance), n_points)
    y = y_true + noise
    
    # å»ºç«‹DataFrame
    df = pd.DataFrame({'x': x, 'y': y})
    
    # åŸ·è¡Œç·šæ€§è¿´æ­¸ (CRISP-DM 4.0 å»ºæ¨¡)
    model = LinearRegression()
    model.fit(x.reshape(-1, 1), y)
    y_pred = model.predict(x.reshape(-1, 1))
    
    # è¨ˆç®—æ®˜å·®ç”¨æ–¼é›¢ç¾¤å€¼æª¢æ¸¬ (CRISP-DM 5.0 è©•ä¼°)
    residuals = np.abs(y - y_pred)
    df['residuals'] = residuals
    
    # è­˜åˆ¥å‰5å€‹é›¢ç¾¤å€¼
    outliers = df.nlargest(5, 'residuals')
    
    # ç¹ªè£½åœ–è¡¨
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ç¹ªè£½è³‡æ–™é»
    ax.scatter(df['x'], df['y'], 
               alpha=0.6, 
               s=30, 
               color='blue', 
               label=f'è³‡æ–™é» (n={n_points})')
    
    # ç¹ªè£½è¿´æ­¸ç·š (ç´…è‰²)
    ax.plot(df['x'], y_pred, 
            color='red', 
            linewidth=3, 
            label='ç·šæ€§è¿´æ­¸ç·š')
    
    # æ¨™è¨˜é›¢ç¾¤å€¼
    for i, (idx, row) in enumerate(outliers.iterrows()):
        ax.annotate(f'é›¢ç¾¤å€¼ {i+1}', 
                   (row['x'], row['y']), 
                   textcoords="offset points", 
                   xytext=(0, 15), 
                   ha='center', 
                   color='purple',
                   fontweight='bold')
        ax.scatter(row['x'], row['y'], 
                  color='purple', 
                  s=150, 
                  edgecolors='black', 
                  linewidth=2,
                  zorder=5)
    
    ax.set_xlabel("X å€¼", fontsize=12)
    ax.set_ylabel("Y å€¼", fontsize=12)
    ax.set_title(f"ç·šæ€§è¿´æ­¸åˆ†æ (y = {coefficient_a:.1f}x + {intercept_b:.1f} + noise)", 
                fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    st.pyplot(fig)

with col2:
    st.subheader("ğŸ“Š æ¨¡å‹çµæœ")
    
    # é¡¯ç¤ºæ¨¡å‹ä¿‚æ•¸
    st.markdown("### ğŸ¯ è¿´æ­¸ä¿‚æ•¸")
    st.metric("æ–œç‡ (a)", f"{model.coef_[0]:.3f}")
    st.metric("æˆªè· (b)", f"{model.intercept_:.3f}")
    
    # è¨ˆç®—RÂ²åˆ†æ•¸
    from sklearn.metrics import r2_score
    r2 = r2_score(y, y_pred)
    st.metric("RÂ² åˆ†æ•¸", f"{r2:.3f}")
    
    # é¡¯ç¤ºé›¢ç¾¤å€¼è³‡è¨Š
    st.markdown("### ğŸ” å‰5å€‹é›¢ç¾¤å€¼")
    outliers_display = outliers[['x', 'y', 'residuals']].copy()
    outliers_display.columns = ['Xå€¼', 'Yå€¼', 'æ®˜å·®']
    outliers_display.index = [f'é›¢ç¾¤å€¼ {i+1}' for i in range(len(outliers_display))]
    st.dataframe(outliers_display.round(3), use_container_width=True)

# åº•éƒ¨è³‡è¨Š
st.markdown("---")
st.markdown("### ğŸ“‹ CRISP-DM æ–¹æ³•è«–èªªæ˜")
st.markdown("""
**CRISP-DM (Cross-Industry Standard Process for Data Mining)** æ˜¯è³‡æ–™æ¢å‹˜çš„æ¨™æº–æµç¨‹ï¼š

1. **å•†æ¥­ç†è§£** - å®šç¾©å°ˆæ¡ˆç›®æ¨™å’Œéœ€æ±‚
2. **è³‡æ–™ç†è§£** - æ”¶é›†å’Œæ¢ç´¢è³‡æ–™
3. **è³‡æ–™æº–å‚™** - æ¸…ç†å’Œè½‰æ›è³‡æ–™
4. **å»ºæ¨¡** - å»ºç«‹é æ¸¬æ¨¡å‹
5. **è©•ä¼°** - è©•ä¼°æ¨¡å‹æ•ˆæœ
6. **éƒ¨ç½²** - éƒ¨ç½²å’Œç›£æ§æ¨¡å‹

æœ¬ç¯„ä¾‹å±•ç¤ºäº†å®Œæ•´çš„CRISP-DMæµç¨‹ï¼Œå¾è³‡æ–™ç”Ÿæˆåˆ°æ¨¡å‹éƒ¨ç½²çš„äº’å‹•å¼é«”é©—ã€‚
""")
